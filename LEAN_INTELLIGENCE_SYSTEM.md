# LEAN INTELLIGENCE SYSTEM - Implementation Specification

## Executive Summary

Build a privacy-first, local intelligence layer for Lean that extracts structured insights from unstructured thoughts. The system learns user patterns without requiring configuration, extracts trackable events conservatively, and surfaces meaningful connections between thoughts, people, and behaviors.

## System Architecture

### Core Components

**Entry Pipeline**
- User types entry ‚Üí Save to DB instantly (<100ms)
- Trigger async enrichment pipeline
- Display enrichment status (‚ö° processing ‚Üí ‚úì complete)
- Store raw entry + enrichments separately

**Intelligence Layers**
1. **Tier 1 (Universal)** - Applied to 100% of entries
2. **Tier 2 (Event)** - Applied when confidence ‚â•0.85
3. **Tier 3 (Patterns)** - Computed from accumulated data
4. **Tier 4 (Insights)** - Higher-order connections

**Storage Strategy**
- Raw entries: Immutable source of truth
- Enrichments: JSONB fields, versioned
- Patterns: Materialized views, refreshed hourly
- Events: Separate table with entry linkage

## Data Models

### Entry Enrichments Table
```
enrichments
- id: UUID (primary)
- entry_id: UUID (references entries)
- emotion: TEXT (constrained vocabulary)
- themes: TEXT[] (max 3, constrained vocabulary)
- people: JSONB (name + context per person)
- urgency: TEXT (low/medium/high)
- actions: TEXT[] (extracted todos/needs)
- questions: JSONB (open questions detected)
- decisions: JSONB (decision points detected)
- confidence_scores: JSONB (per-field confidence)
- enrichment_version: TEXT
- created_at: TIMESTAMP
```

### Events Table
```
events
- id: UUID (primary)
- user_id: UUID
- entry_id: UUID (source entry)
- type: TEXT (exercise/consumption/spend/sleep/meeting/etc)
- subtype: TEXT (squat/coffee/groceries/etc)
- metrics: JSONB (weight_kg, distance_km, amount, duration_min, etc)
- context: JSONB (people present, location, work-related, etc)
- confidence: FLOAT
- extraction_method: TEXT (metrics/vlp/perfective)
- user_validated: BOOLEAN
- created_at: TIMESTAMP
```

### Validated Logger Phrases (VLP)
```
vlps
- id: UUID
- user_id: UUID
- phrase: TEXT
- phrase_normalized: TEXT
- event_type: TEXT
- usage_count: INTEGER
- first_seen: TIMESTAMP
- last_promoted: TIMESTAMP
- user_action: TEXT (validated/rejected/null)
- variations: TEXT[]
```

### Person Entities
```
person_entities
- id: UUID
- user_id: UUID
- name: TEXT
- name_normalized: TEXT
- relationship: TEXT (manager/colleague/friend/family/client)
- sentiment_scores: JSONB (track per-mention sentiment)
- contexts: TEXT[] (work/personal/social)
- interaction_types: TEXT[] (meeting/feedback/conflict/collaboration)
- mention_count: INTEGER
- first_mention: TIMESTAMP
- last_mention: TIMESTAMP
```

### Patterns Tables

**Temporal Patterns**
```
temporal_patterns
- user_id: UUID
- time_block: TEXT (morning/afternoon/evening/night)
- day_type: TEXT (weekday/weekend)
- dominant_emotion: TEXT
- dominant_themes: TEXT[]
- entry_frequency: FLOAT
- pattern_confidence: FLOAT
```

**Causal Patterns**
```
causal_patterns
- user_id: UUID
- trigger_type: TEXT
- trigger_pattern: JSONB
- outcome_type: TEXT
- outcome_pattern: JSONB
- timeframe: TEXT (0-2h/2-6h/6-24h/1-3d)
- occurrence_count: INTEGER
- confidence: FLOAT
- last_observed: TIMESTAMP
```

**User Context**
```
user_facts
- user_id: UUID
- category: TEXT (work/personal/people/location)
- fact: TEXT
- entity_refs: TEXT[] (linked entities)
- added_at: TIMESTAMP
- active: BOOLEAN
```

## Intelligence Pipeline

### Stage 1: Entry Processing (Synchronous)
1. Save raw entry
2. Return success immediately
3. Queue enrichment job

### Stage 2: Tier 1 Enrichment (Async, <3s)

**Emotion Detection**
- Vocabulary: frustrated, anxious, excited, content, calm, energized, tired, sad, angry, overwhelmed, focused, grateful, contemplative, curious, scattered, accomplished, lonely, bored, neutral
- Method: LLM with fallback to keyword patterns
- Constraints: Single emotion per entry

**Theme Classification**
- Vocabulary: work, personal, health, relationships, finance, creative, tech, learning, leisure, reflection
- Method: LLM with fallback to keyword matching
- Constraints: Maximum 3 themes, ordered by relevance

**People Extraction**
- Method: NER + capitalization patterns + user context
- Enhancement: Track sentiment about person in this entry
- Store: Name + sentiment + context of mention

**Urgency Detection**
- Levels: low, medium, high
- Signals: Time markers, action words, emotional intensity
- Method: Rule-based + LLM validation

**Action Extraction**
- Patterns: "need to", "must", "todo:", "should", "have to"
- Method: Regex + LLM validation
- Output: Array of actionable items

**Question Detection**
- Types: open-ended, yes/no, rhetorical
- Method: Punctuation + sentence structure + LLM
- Track: Question lifecycle (open ‚Üí answered)

### Stage 3: Tier 2 Event Extraction (Async, <3s)

**‚ú® NEW: LLM-Based Event Extraction (October 2025)**
- **Single API call** extracts both enrichment AND events
- **Claude AI** understands natural language variations
- **500+ lines of regex removed** - handles infinite variations!

**LLM Confidence Scoring**
- 0.9-1.0: Explicit metrics + past tense ("ran 5km", "had 3 coffees")
- 0.7-0.9: Past activity, no metrics ("went running", "had coffee")
- 0.5-0.7: Ambiguous mention ("coffee break", "gym day")
- 0.0-0.3: Future intent ("will run", "planning to swim")

**Extraction Thresholds**
- Extract: confidence ‚â• 0.85
- Shadow (learn but don't save): 0.65-0.85
- Ignore: <0.65

**Event Types**
- exercise (subtypes: squat, run, walk, yoga, swim, bike, weights)
- consumption (subtypes: alcohol, caffeine, food, supplements)
- spend (subtypes: groceries, transport, entertainment, bills)
- sleep (metrics: duration, quality)
- meeting (subtypes: 1:1, team, client, interview)
- health (subtypes: symptom, medication, appointment)

**Examples That Work Now (Failed with Regex)**
- "Coffee #3 already" ‚Üí consumption.coffee, count:3, confidence:0.95
- "Swam 40 laps in 35 minutes" ‚Üí exercise.swim, laps:40, duration:35, confidence:1.0
- "Quick gym session" ‚Üí exercise.gym, confidence:0.70
- "2hr meeting with Sarah" ‚Üí meeting, duration:120, attendees:['Sarah'], confidence:0.90

### Stage 4: Pattern Detection (Batch, hourly)

**VLP Promotion**
- Trigger: Phrase used 3+ times in 28 days
- Validation: Check for consistency in context
- Auto-promote: If confidence >0.90
- User-promote: Present in UI for confirmation

**Person Relationships**
- Analyze co-occurrence with themes/contexts
- Infer relationship type from interaction patterns
- Calculate average sentiment
- Track interaction frequency

**Temporal Patterns**
- Segment by: hour blocks, day of week
- Calculate: dominant emotions, themes, entry frequency
- Identify: Peak productivity, stress times, reflection periods

**Causal Chains**
- Window: Look for patterns within time windows
- Correlation: Track A‚ÜíB occurrences
- Threshold: Minimum 3 occurrences for pattern
- Types: stress‚Üícoping, activity‚Üímood, trigger‚Üíbehavior

### Stage 5: Insight Generation (Batch, daily)

**Cross-Pattern Analysis**
- People + emotion correlations
- Time + theme patterns
- Event + outcome chains
- Question ‚Üí answer paths

**Anomaly Detection**
- Unusual emotion for time period
- Break in established patterns
- New people/contexts appearing
- Urgency spikes

## User Experience

### Entry Flow
1. User types entry
2. Instant save (<100ms)
3. Lightning icon appears (enriching)
4. Check mark appears (2s, then fades)
5. Enrichments silently added to entry

### Command Enhancements

**/context** - Manage user facts
- `/context add [fact]` - Add context
- `/context list` - Show all facts
- `/context remove [id]` - Remove fact
- Categories: work, personal, people, location

**/patterns** - View learned patterns
- Show VLPs with usage count
- Display people relationships
- Reveal temporal patterns
- Surface causal chains
- One-tap validation/rejection

**/events** - View tracked events
- Filter by type/date/person
- Show confidence scores
- Enable bulk validation
- Export to CSV

**/insights** - Higher-order patterns
- Weekly emotion trends
- People correlation insights
- Habit formation tracking
- Question resolution paths

### Pattern Validation UI

**For VLP Detection**
```
üí° Pattern detected: "leg day!" (used 3 times)
Track this as: [Exercise - Leg workout]
[Always track] [Never track] [Ask later]
```

**For Causal Patterns**
```
üîó Pattern noticed: "stressful meeting" ‚Üí "whiskey" (within 6 hours)
This happened 4 times in the past month.
[Acknowledge] [Not a pattern] [Show details]
```

### Privacy Controls

**/intelligence** - Manage intelligence settings
- Toggle extraction layers on/off
- Set confidence thresholds
- Clear learned patterns
- Export all intelligence data
- Delete all enrichments

## LLM Integration

### Model Selection
- Primary: Claude 3.5 Sonnet (via Supabase Edge Functions)
- Fallback: Pattern-based extraction (built into Edge Function)
- Constraints: Single API call per entry via serverless function

### Architecture: Supabase Edge Functions Approach

**Why Edge Functions:**
1. **Security**: API keys stored server-side, never exposed to client
2. **Cost Control**: Central API key management, usage monitoring
3. **Performance**: Edge locations for low latency
4. **Reliability**: Built-in fallback when API fails
5. **Scalability**: Serverless auto-scaling

**Implementation:**
```typescript
// /supabase/functions/enrich-entry/index.ts
- Deployed as Supabase Edge Function
- Handles Claude API calls securely
- Returns enrichment or fallback mock data
- Processes in <3s with timeout handling
```

**Client Integration:**
```dart
// Flutter app calls Edge Function
final response = await supabase.functions.invoke(
  'enrich-entry',
  body: {
    'entryText': entry.content,
    'entryId': entry.id,
    'userContext': userFacts, // User's context facts
  }
);
```

### Prompt Engineering

**Current Tier 1 Enrichment Prompt (Production)**
1. User context facts (if any) passed as system context
2. Constrained vocabularies for each field
3. Entry text for analysis
4. JSON schema enforcement
5. Critical instructions to prevent false extractions (especially people names)

**Edge Function Fallback Logic**
- If Claude API fails ‚Üí return mock enrichment
- Mock uses keyword detection for basic accuracy
- Ensures zero downtime for enrichment pipeline

### Response Parsing
- Edge Function validates JSON response
- Transforms to Flutter-compatible format
- Falls back to mock on parse failure
- Returns success/failure status with enrichment

## Testing Strategy

### Unit Tests
- Emotion detection accuracy
- Theme classification precision
- Event extraction confidence calculation
- VLP promotion logic
- Pattern detection algorithms

### Integration Tests
- Full pipeline processing
- LLM fallback handling
- Database transaction integrity
- Pattern batch processing

### User Acceptance Criteria
- Tier 1 accuracy >85%
- Event extraction precision >90%
- VLP false positive rate <5%
- Pattern relevance >80%
- Processing time <3s for Tier 1, <5s total

## Rollout Plan

### ‚úÖ Phase 1: Foundation (COMPLETED - 2025-10-21)
- ‚úÖ Database schema setup (Supabase + SQLite)
- ‚úÖ Basic enrichment pipeline (queue-based processing)
- ‚úÖ Tier 1 extraction with REAL Claude API (emotion, themes, people, urgency)
- ‚úÖ Visual indicators (‚ö° processing ‚Üí ‚úÖ complete)
- ‚úÖ Enrichment model with all fields from spec
- ‚úÖ Service layer with background processing
- ‚úÖ /context command implementation (add, list, remove, clear)
- ‚úÖ Supabase Edge Functions for secure LLM integration
- ‚úÖ Context persistence across sessions - FIXED

**What's Working:**
- Real-time AI enrichment using Claude 3.5 Sonnet via Edge Functions
- Accurate sentiment detection (contemplative, positive, energized, etc.)
- Smart topic categorization (family, health, work, relationships)
- Reliable people extraction (Mom, Dad, Samantha, Emma, Robert, Chen)
- Priority level assignment based on content
- /context commands persist data across sessions
- Enrichments display as colored tags on entries
- Processing completes in ~2-3 seconds
- Fallback to mock enrichment if API fails

**Live Features:**
- **Sentiment Tags**: Green (positive), Red (negative/anxious), Gray (neutral)
- **Topic Tags**: Blue/Indigo (work, family, health, relationships)
- **People Tags**: Orange/Amber (extracted names)
- **Priority Tags**: Red (high), Orange (medium), Gray (low)
- **/context Command**: Store facts about yourself that enhance AI analysis
  - `/context add I work at Google` - Add personal context
  - `/context list` - View all stored facts
  - `/context remove [id]` - Remove specific fact
  - `/context clear` - Clear all facts

**Fixed Issues:**
- ‚úÖ Context persistence on refresh/restart (loads from Supabase on init)
- ‚úÖ Supabase sync for enrichments and user facts
- ‚úÖ Proper session restoration with context loading

### üöß Phase 2: Event Intelligence (90% Complete - 2025-10-21)

#### Completed Components:
- ‚úÖ Database schema (events, vlps, shadow_events tables)
- ‚úÖ Event model with type-safe metrics and context
- ‚úÖ EventExtractionService with confidence scoring
- ‚úÖ Regex-based extraction for exercise, spend, sleep, meetings
- ‚úÖ Confidence calculation (metrics +0.50, perfective +0.25, time +0.25, VLP +0.30)
- ‚úÖ Shadow events for learning (0.65-0.85 confidence)
- ‚úÖ Integration with enrichment pipeline
- ‚úÖ /events command implementation (has bug)
- ‚úÖ Event statistics function
- ‚úÖ VLP model and database structure

#### Known Issues:
- üêõ /events command shows null error (partial fix applied)
- üêõ Time display shows "just now" for all entries instead of actual time
- üîß Regex approach is brittle (should move to LLM-based extraction)
- üî≤ VLP auto-promotion not yet implemented
- üî≤ User validation UI not built

#### Sample Extractions Working:
- "Ran 13km in 82 minutes this morning" ‚Üí exercise.run (1.0 confidence) ‚úÖ
- "Spent $245 on groceries" ‚Üí spend.groceries (1.0 confidence) ‚úÖ
- "2 hour meeting with Sarah" ‚Üí meeting (1.0 confidence) ‚úÖ
- "Cycled 15km along the coast today" ‚Üí exercise.cycle (1.0 confidence) ‚úÖ

### üî≤ Phase 3: Pattern Recognition (Week 5-6)
- Temporal pattern detection
- Person relationship inference
- Causal chain identification
- /patterns command with validation UI

### üî≤ Phase 4: Advanced Intelligence (Week 7-8)
- Question tracking
- Decision detection
- Insight generation
- /insights command

### üî≤ Phase 5: Optimization (Week 9-10)
- Confidence calibration from user feedback
- Prompt optimization
- Performance tuning
- Privacy controls UI

## Success Metrics

### Accuracy Metrics
- Tier 1 extraction accuracy: >85%
- Event precision: >90%
- VLP validation rate: >70%
- Pattern acceptance rate: >60%

### Performance Metrics
- Enrichment latency: <3s (p95)
- Pattern computation: <60s (hourly batch)
- API cost: <$0.001 per entry

### User Value Metrics
- Insights discovered per user per month: >3
- Pattern validation actions: >1 per week
- Event tracking adoption: >40% of users
- Context facts added: >5 per user

## Configuration

### Environment Variables
```
ANTHROPIC_API_KEY - Claude API access
INTELLIGENCE_ENABLED - Master toggle
DEFAULT_CONFIDENCE_THRESHOLD - Event extraction threshold (0.85)
PATTERN_BATCH_INTERVAL - Pattern detection frequency (3600s)
VLP_PROMOTION_THRESHOLD - Usage count for auto-promotion (3)
VLP_PROMOTION_WINDOW - Time window for usage (28 days)
```

### Feature Flags
- TIER1_ENRICHMENT - Enable basic enrichment
- TIER2_EVENTS - Enable event extraction
- VLP_DETECTION - Enable phrase learning
- PATTERN_DETECTION - Enable pattern recognition
- CAUSAL_CHAINS - Enable causal analysis
- INSIGHT_GENERATION - Enable insight creation

## Security & Privacy

### Data Handling
- All processing happens on user's data only
- No cross-user pattern detection
- User can delete all intelligence data
- Export includes all extracted intelligence

### API Security
- API keys stored encrypted
- Rate limiting per user
- Fallback to local processing
- No PII in logs

## Maintenance

### Monitoring
- Track extraction accuracy weekly
- Monitor API costs daily
- Review failed extractions
- Analyze user validation patterns

### Iteration
- Weekly prompt optimization based on failures
- Monthly vocabulary updates based on usage
- Quarterly pattern algorithm improvements
- Continuous confidence threshold tuning

## Edge Cases

### Handle These Scenarios
- Entries in multiple languages
- Code snippets in entries
- Very long entries (>1000 chars)
- Rapid successive entries
- Offline mode (no API access)
- Users with 10k+ entries
- Timezone changes
- Data export/import cycles

## Implementation Notes

### Critical Principles
1. **Never block entry saving** - Intelligence is always async
2. **Fail gracefully** - Always have fallback extraction
3. **User control** - Every pattern can be rejected
4. **Privacy first** - No data leaves user's control
5. **Conservative extraction** - High precision over recall
6. **Learn from usage** - Patterns improve with feedback
7. **Transparent intelligence** - Show confidence and reasoning

### Development Sequence (Actual Progress)
1. ‚úÖ Build data models (Enrichment class with all fields)
2. ‚úÖ Implement Tier 1 pipeline (queue-based async processing)
3. ‚úÖ Add LLM integration with fallbacks (Claude API via Edge Functions)
4. ‚úÖ Create /context command (user facts management)
5. ‚úÖ Fix session persistence and restoration
6. ‚úÖ Deploy enrichment system to production
7. ‚úÖ Build event extraction with confidence scoring
8. ‚úÖ Create Event and VLP data models
9. ‚úÖ Implement regex-based extraction for high-confidence events
10. ‚úÖ Add shadow event tracking for learning
11. ‚úÖ Create /events command (needs debugging)
12. ‚úÖ Implement confidence scoring algorithm
13. ‚úÖ Add event statistics and metrics aggregation
14. üêõ Fix /events null error and time display issue
15. üî≤ Move to LLM-based event extraction (replace regex)
16. üî≤ Create VLP auto-promotion system
17. üî≤ Implement validation UI
18. üî≤ Add /patterns command interface

## Implementation Details (Flutter/Dart)

### Database Schema Created
```sql
-- Supabase enrichments table
CREATE TABLE enrichments (
    id UUID PRIMARY KEY,
    entry_id UUID REFERENCES entries(id),
    user_id UUID REFERENCES auth.users(id),
    emotion TEXT,
    themes TEXT[],
    people JSONB,
    urgency TEXT DEFAULT 'none',
    actions TEXT[],
    questions JSONB,
    decisions JSONB,
    confidence_scores JSONB,
    enrichment_version TEXT DEFAULT '1.0',
    processing_status TEXT DEFAULT 'pending',
    processing_time_ms INTEGER,
    error_message TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);
```

### Files Created/Modified
- `/lib/models/enrichment.dart` - Enrichment model with all fields
- `/lib/services/enrichment_service.dart` - Queue processing, mock enrichment
- `/lib/services/supabase_service.dart` - Added enrichment CRUD methods
- `/lib/services/database_service.dart` - Added local enrichments table
- `/lib/widgets/entry_widget.dart` - Visual status indicators, enriched badges
- `/lib/services/entry_provider.dart` - Auto-queue on entry save
- `/supabase/migrations/001_create_enrichments_table.sql` - Schema migration

### Mock Enrichment Detection (Current)
**Emotions:** happy/great ‚Üí excited, sad/down ‚Üí sad, stress/anxious ‚Üí anxious
**Themes:** work/meeting ‚Üí work, exercise/gym ‚Üí health, money/budget ‚Üí finance
**Urgency:** urgent/asap ‚Üí high, soon/today ‚Üí medium
**People:** Capitalized names (John, Sarah, etc.)

## Next Small Steps

### ‚úÖ Phase 1 Complete! AI Enrichment is Live

The intelligence system is now operational with:
- Real-time Claude AI enrichment
- Persistent user context (/context command)
- Accurate extraction of sentiment, topics, people, and priority
- Beautiful tag-based visualization
- Session persistence and restoration

### Next Critical Fixes

#### üö® Immediate Issues (Fix First)
1. **Debug /events null error**
   - Event.fromJson may have null handling issues
   - Check extraction_method and updated_at fields
   - Verify database data matches model expectations

2. **Fix time display "just now" bug**
   - All entries show "just now" instead of actual time
   - Likely relative time formatting issue
   - Check Entry.createdAt and display logic

#### üîß Major Improvement Needed
3. **Replace Regex with LLM-Based Event Extraction**
   - Current regex approach is brittle and frustrating
   - Move extraction to Supabase Edge Function
   - Use Claude to extract events with enrichments
   - Benefits:
     - No more regex pattern maintenance
     - Handles natural language variations
     - Better context understanding
     - Single API call for both enrichment + events

#### üìä Session Stats (2025-10-21)
- Files created: 5 (SQL migration, Event model, EventExtractionService, test file, /events command)
- Lines of code: ~2000+
- Regex patterns written: 8 (and they're still not perfect!)
- Time spent on regex debugging: Too much! üò§
- Events successfully extracted: Yes, but with pain
- Developer satisfaction: Low (regex fatigue)

### üí° Recommendation: Pivot to LLM-Based Extraction

**Current Pain Points with Regex:**
- "Cycled" not detected ‚Üí had to add pattern
- "Biked" not detected ‚Üí had to add pattern
- "Swam" not detected ‚Üí had to add pattern
- Meeting confidence too low ‚Üí had to tweak scoring
- Every new verb requires code changes
- Fragile and frustrating to maintain

**Proposed LLM Solution:**
1. Update Edge Function to extract events
2. Claude understands all variations naturally
3. One API call for enrichment + events
4. No more client-side regex maintenance
5. Better accuracy and context understanding

**Implementation Effort:**
- 1 hour to update Edge Function
- 30 min to update client to receive events
- Delete 500+ lines of regex code! üéâ

### Phase 3: Pattern Recognition (Week 3-4)
1. **Temporal Patterns**
   - Analyze entry timing (morning/afternoon/evening)
   - Track emotion/theme patterns by time
   - Identify peak productivity periods

2. **Person Relationships**
   - Track sentiment when people are mentioned
   - Infer relationship types from context
   - Build interaction frequency heatmaps

3. **Causal Chains**
   - Detect A‚ÜíB patterns (stress‚Üícoping, activity‚Üímood)
   - Require 3+ occurrences for pattern confirmation
   - Surface insights to user

### Testing Checklist
- [x] Mock enrichment processes entries
- [x] Visual indicators work (‚ö° ‚Üí ‚úÖ)
- [x] Badges display enriched data
- [x] /context commands work (add/list/remove/clear)
- [x] Edge Function deployed and callable
- [x] Context facts persist after logout/login
- [x] Real LLM API returns valid enrichments
- [x] Enrichments sync to Supabase properly
- [x] Session restoration with context loading
- [x] Accurate sentiment detection
- [x] Proper people extraction
- [x] Topic categorization working
- [x] Priority level assignment
- [ ] /patterns command shows insights
- [ ] Event extraction with confidence scores
- [ ] VLP detection and promotion

This specification provides complete implementation guidance for building Lean's intelligence system from scratch, focusing on practical extraction, user trust, and meaningful insights.
